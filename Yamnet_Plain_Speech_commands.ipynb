{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yamnet_Plain_Speech_commands.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4nBdvnZmbsL"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as keras\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "# Set seed for experiment reproducibility\n",
        "#seed = 42\n",
        "#tf.random.set_seed(seed)\n",
        "#np.random.seed(seed)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp27RunVmqAT",
        "outputId": "9305dc3d-b6cd-4821-8b78-7607c7b8fbef"
      },
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n",
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKj9Pst_h_jY",
        "outputId": "b8c838ab-06a5-4f57-80b9-376f110b425e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun 13 15:06:46 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muTu3WVDmtZ3",
        "outputId": "2c2cb588-3388-4f0e-d39c-5cef5b611c45"
      },
      "source": [
        "# Download folder and unzip it\n",
        "data_dir = pathlib.Path('data/mini_speech_commands')\n",
        "if not data_dir.exists():\n",
        "  tf.keras.utils.get_file(\n",
        "      'mini_speech_commands.zip',\n",
        "      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir='data')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\n",
            "182083584/182082353 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLtzkqMZoriw",
        "outputId": "bf1d3b93-9519-4966-b781-f49ebce3a570"
      },
      "source": [
        "# Print commands\n",
        "commands = []\n",
        "commands.append('down')\n",
        "commands.append('go')\n",
        "commands.append('left')\n",
        "commands.append('no')\n",
        "commands.append('right')\n",
        "commands.append('stop')\n",
        "commands.append('up')\n",
        "commands.append('yes')\n",
        "\n",
        "commands = np.array(commands)#np.array(tf.io.gfile.listdir(str(data_dir)))\n",
        "#commands = commands[commands != 'README.md']\n",
        "print('Commands:', commands)\n",
        "\n",
        "# Shuffle audio samples and print some info\n",
        "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
        "filenames = tf.random.shuffle(filenames)\n",
        "print(type(filenames))\n",
        "num_samples = len(filenames)\n",
        "print('Number of total examples:', num_samples)\n",
        "print('Number of examples per label:', len(tf.io.gfile.listdir(str(data_dir/commands[0]))))\n",
        "print('Example file tensor:', filenames[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Commands: ['down' 'go' 'left' 'no' 'right' 'stop' 'up' 'yes']\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Number of total examples: 8000\n",
            "Number of examples per label: 1000\n",
            "Example file tensor: tf.Tensor(b'data/mini_speech_commands/no/c103a2d5_nohash_1.wav', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xplb9y16nWbV"
      },
      "source": [
        "'''\n",
        "The audio file will initially be read as a binary file, which you'll want to convert into a numerical tensor.\n",
        "To load an audio file, you will use tf.audio.decode_wav, which returns the WAV-encoded audio as a Tensor and the sample rate.\n",
        "A WAV file contains time series data with a set number of samples per second. Each sample represents the amplitude of the audio signal at that specific time.\n",
        "In a 16-bit system, like the files in mini_speech_commands, the values range from -32768 to 32767. The sample rate for this dataset is 16kHz. \n",
        "Note that tf.audio.decode_wav will normalize the values to the range [-1.0, 1.0].\n",
        "'''\n",
        "def decode_audio(audio_binary):\n",
        "  audio, _ = tf.audio.decode_wav(audio_binary)\n",
        "  return tf.squeeze(audio, axis=-1)\n",
        "\n",
        "def get_label(file_path):\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "\n",
        "  # Note: You'll use indexing here instead of tuple unpacking to enable this \n",
        "  # to work in a TensorFlow graph.\n",
        "  return parts[-2]\n",
        "\n",
        "def get_waveform_and_label_in_integer(file_path):\n",
        "  label = get_label(file_path)\n",
        "  #print(label.numpy().decode('utf-8'))\n",
        "  label = tf.argmax(label == commands)\n",
        "  label = tf.cast(label, tf.int32)  \n",
        "  audio_binary = tf.io.read_file(file_path)\n",
        "  waveform = decode_audio(audio_binary)\n",
        "  return waveform, label\n",
        "\n",
        "# We need the waveforms to have a similar length.\n",
        "# This can be done by simply zero padding the audio clips that are shorter than one second.\n",
        "\n",
        "def zero_pad_the_waveforms(waveform):\n",
        "  # Padding for files with less than 16000 samples\n",
        "  zero_padding = tf.zeros([16000] - tf.shape(waveform), dtype=tf.float32)\n",
        "\n",
        "  # Concatenate audio with padding so that all audio clips will be of the \n",
        "  # same length\n",
        "  waveform = tf.cast(waveform, tf.float32)\n",
        "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
        "\n",
        "  return equal_length"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHS1Q10dRHFa"
      },
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "for i in filenames:\n",
        "  #print(i)\n",
        "  train_x.append(zero_pad_the_waveforms(get_waveform_and_label_in_integer(i)[0]))\n",
        "  train_y.append(get_waveform_and_label_in_integer(i)[1])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYeDiCuiRGCz",
        "outputId": "8aa03728-06cd-45ce-8edc-97287b0c55a0"
      },
      "source": [
        "print(len(train_x))\n",
        "print(filenames[:7])\n",
        "print(train_x[:7])\n",
        "print(train_y[:7])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000\n",
            "tf.Tensor(\n",
            "[b'data/mini_speech_commands/no/c103a2d5_nohash_1.wav'\n",
            " b'data/mini_speech_commands/left/b087aa0e_nohash_0.wav'\n",
            " b'data/mini_speech_commands/left/c37a72d3_nohash_2.wav'\n",
            " b'data/mini_speech_commands/left/11b1df78_nohash_1.wav'\n",
            " b'data/mini_speech_commands/down/0132a06d_nohash_1.wav'\n",
            " b'data/mini_speech_commands/down/b19f7f5f_nohash_1.wav'\n",
            " b'data/mini_speech_commands/yes/4f2be90f_nohash_0.wav'], shape=(7,), dtype=string)\n",
            "[<tf.Tensor: shape=(16000,), dtype=float32, numpy=\n",
            "array([-0.0050354 , -0.0067749 , -0.00576782, ...,  0.00259399,\n",
            "        0.00476074,  0.00680542], dtype=float32)>, <tf.Tensor: shape=(16000,), dtype=float32, numpy=\n",
            "array([-0.0005188 , -0.00091553, -0.00064087, ...,  0.        ,\n",
            "        0.        ,  0.        ], dtype=float32)>, <tf.Tensor: shape=(16000,), dtype=float32, numpy=\n",
            "array([ 3.0517578e-05, -1.5258789e-04, -1.8310547e-04, ...,\n",
            "        1.1901855e-03,  1.2207031e-03,  1.4038086e-03], dtype=float32)>, <tf.Tensor: shape=(16000,), dtype=float32, numpy=\n",
            "array([-0.00939941, -0.00985718, -0.01089478, ..., -0.01184082,\n",
            "       -0.00939941, -0.00997925], dtype=float32)>, <tf.Tensor: shape=(16000,), dtype=float32, numpy=\n",
            "array([ 1.5258789e-04,  1.5258789e-04,  9.1552734e-05, ...,\n",
            "       -1.8310547e-04, -1.8310547e-04, -1.5258789e-04], dtype=float32)>, <tf.Tensor: shape=(16000,), dtype=float32, numpy=\n",
            "array([ 0.0000000e+00,  2.1362305e-04,  0.0000000e+00, ...,\n",
            "        9.1552734e-05,  3.0517578e-05, -2.7465820e-04], dtype=float32)>, <tf.Tensor: shape=(16000,), dtype=float32, numpy=\n",
            "array([-0.0017395 , -0.00314331, -0.00256348, ..., -0.00933838,\n",
            "       -0.00683594, -0.00283813], dtype=float32)>]\n",
            "[<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(), dtype=int32, numpy=7>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jMgq56WUAQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2673825e-012e-4450-a442-8c127126add4"
      },
      "source": [
        "train_x = tf.convert_to_tensor(train_x)\n",
        "train_y = tf.convert_to_tensor(train_y)\n",
        "print(len(train_x))\n",
        "print(len(train_y))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000\n",
            "8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxaPgjMf04zL",
        "outputId": "90bc8ce0-1167-4f1d-c1cc-fbea5bd398f0"
      },
      "source": [
        "print(train_x[:4])\n",
        "print(train_y[:4])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-5.0354004e-03 -6.7749023e-03 -5.7678223e-03 ...  2.5939941e-03\n",
            "   4.7607422e-03  6.8054199e-03]\n",
            " [-5.1879883e-04 -9.1552734e-04 -6.4086914e-04 ...  0.0000000e+00\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [ 3.0517578e-05 -1.5258789e-04 -1.8310547e-04 ...  1.1901855e-03\n",
            "   1.2207031e-03  1.4038086e-03]\n",
            " [-9.3994141e-03 -9.8571777e-03 -1.0894775e-02 ... -1.1840820e-02\n",
            "  -9.3994141e-03 -9.9792480e-03]], shape=(4, 16000), dtype=float32)\n",
            "tf.Tensor([3 2 2 2], shape=(4,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh1OZUrJw07a",
        "outputId": "2fe100ff-4d6f-4e1e-ffa4-9d09306a9f84"
      },
      "source": [
        "numpy_y = train_y.numpy()\n",
        "print(numpy_y)\n",
        "print(tf.convert_to_tensor(numpy_y[:4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 4 0 ... 3 3 7]\n",
            "tf.Tensor([5 4 0 3], shape=(4,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O-t_navYRMz"
      },
      "source": [
        "# Yamnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgVIlfJbYS7x"
      },
      "source": [
        "# Download the model from TFHub\n",
        "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
        "yamnet_model = hub.load(yamnet_model_handle)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTaogiDRYTiT",
        "outputId": "af7e3ec6-022d-40be-8ea9-ae8a2d70f0fc"
      },
      "source": [
        "# Print the classes\n",
        "class_map_path = yamnet_model.class_map_path().numpy().decode('utf-8')\n",
        "class_names =list(pd.read_csv(class_map_path)['display_name'])\n",
        "\n",
        "for name in class_names[:20]:\n",
        "  print(name)\n",
        "print('...')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Speech\n",
            "Child speech, kid speaking\n",
            "Conversation\n",
            "Narration, monologue\n",
            "Babbling\n",
            "Speech synthesizer\n",
            "Shout\n",
            "Bellow\n",
            "Whoop\n",
            "Yell\n",
            "Children shouting\n",
            "Screaming\n",
            "Whispering\n",
            "Laughter\n",
            "Baby laughter\n",
            "Giggle\n",
            "Snicker\n",
            "Belly laugh\n",
            "Chuckle, chortle\n",
            "Crying, sobbing\n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P29qsVHWSoh"
      },
      "source": [
        "# applies the embedding extraction model to a wav data\n",
        "def extract_embedding_data(wav_data):\n",
        "  ''' run YAMNet to extract embedding from the wav data '''\n",
        "  #print(len(wav_data))\n",
        "  scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
        "  #num_embeddings = tf.shape(embeddings)[0]\n",
        "  return embeddings\n",
        "\n",
        "# applies the embedding extraction model to a wav data\n",
        "def extract_embedding_data_one_output(wav_data):\n",
        "  ''' run YAMNet to extract embedding from the wav data '''\n",
        "  scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
        "  embeddings = tf.reduce_mean(embeddings, 0)\n",
        "  return embeddings\n",
        "\n",
        "new_array = []\n",
        "\n",
        "for i in train_x:\n",
        "  #print(len(i))\n",
        "  new_array.append(extract_embedding_data_one_output(i))\n",
        "  #new_array.append(extract_embedding_data(i))\n",
        "\n",
        "yamnet_train_x = tf.convert_to_tensor(new_array)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZC8Cxh3YEV0",
        "outputId": "eed28535-83eb-412b-9a75-a917c4c2a00d"
      },
      "source": [
        "print(len(yamnet_train_x))\n",
        "print(yamnet_train_x[:1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000\n",
            "tf.Tensor([[0.03142092 0.39526838 0.13033617 ... 0.3167366  0.0062078  0.        ]], shape=(1, 1024), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMtM8rRJcKv2",
        "outputId": "2e7ac5f1-acc6-480c-f514-8178376e301d"
      },
      "source": [
        "my_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(1024), dtype=tf.float32,\n",
        "                          name='input_embedding'),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(commands))\n",
        "], name='my_model')\n",
        "\n",
        "my_model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 4104      \n",
            "=================================================================\n",
            "Total params: 528,904\n",
            "Trainable params: 528,904\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2NRLuW4cobr"
      },
      "source": [
        "my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                            patience=3,\n",
        "                                            restore_best_weights=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6xPZ0iTctvK",
        "outputId": "62c9535f-40db-42f3-beeb-f93b2d4ecca4"
      },
      "source": [
        "history = my_model.fit(yamnet_train_x,train_y,\n",
        "                       epochs=40,\n",
        "                       validation_split=0.2,\n",
        "                       callbacks=callback,\n",
        "                       batch_size=32,\n",
        "                       verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 1.8171 - accuracy: 0.3327 - val_loss: 1.6459 - val_accuracy: 0.4375\n",
            "Epoch 2/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.5309 - accuracy: 0.4447 - val_loss: 1.4570 - val_accuracy: 0.4800\n",
            "Epoch 3/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.4972 - val_loss: 1.4453 - val_accuracy: 0.4725\n",
            "Epoch 4/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.3278 - accuracy: 0.5300 - val_loss: 1.3791 - val_accuracy: 0.5138\n",
            "Epoch 5/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.2625 - accuracy: 0.5461 - val_loss: 1.3292 - val_accuracy: 0.5131\n",
            "Epoch 6/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.1963 - accuracy: 0.5698 - val_loss: 1.2915 - val_accuracy: 0.5294\n",
            "Epoch 7/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.1404 - accuracy: 0.5881 - val_loss: 1.3006 - val_accuracy: 0.5256\n",
            "Epoch 8/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.0843 - accuracy: 0.6089 - val_loss: 1.3362 - val_accuracy: 0.5138\n",
            "Epoch 9/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.0426 - accuracy: 0.6244 - val_loss: 1.3364 - val_accuracy: 0.5194\n",
            "Epoch 10/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.9877 - accuracy: 0.6483 - val_loss: 1.2950 - val_accuracy: 0.5281\n",
            "Epoch 11/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.9500 - accuracy: 0.6620 - val_loss: 1.2608 - val_accuracy: 0.5444\n",
            "Epoch 12/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.8911 - accuracy: 0.6900 - val_loss: 1.3058 - val_accuracy: 0.5437\n",
            "Epoch 13/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.8443 - accuracy: 0.7061 - val_loss: 1.3444 - val_accuracy: 0.5163\n",
            "Epoch 14/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.8000 - accuracy: 0.7205 - val_loss: 1.2748 - val_accuracy: 0.5431\n",
            "Epoch 15/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.7451 - accuracy: 0.7470 - val_loss: 1.3007 - val_accuracy: 0.5494\n",
            "Epoch 16/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.7102 - accuracy: 0.7613 - val_loss: 1.3281 - val_accuracy: 0.5356\n",
            "Epoch 17/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.7784 - val_loss: 1.3031 - val_accuracy: 0.5362\n",
            "Epoch 18/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.7967 - val_loss: 1.3427 - val_accuracy: 0.5394\n",
            "Epoch 19/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.8072 - val_loss: 1.4254 - val_accuracy: 0.5250\n",
            "Epoch 20/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.8228 - val_loss: 1.3892 - val_accuracy: 0.5475\n",
            "Epoch 21/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8394 - val_loss: 1.3982 - val_accuracy: 0.5425\n",
            "Epoch 22/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8528 - val_loss: 1.4524 - val_accuracy: 0.5150\n",
            "Epoch 23/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8670 - val_loss: 1.4448 - val_accuracy: 0.5325\n",
            "Epoch 24/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8766 - val_loss: 1.4472 - val_accuracy: 0.5381\n",
            "Epoch 25/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8873 - val_loss: 1.4788 - val_accuracy: 0.5444\n",
            "Epoch 26/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.9028 - val_loss: 1.5586 - val_accuracy: 0.5213\n",
            "Epoch 27/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.9130 - val_loss: 1.5236 - val_accuracy: 0.5437\n",
            "Epoch 28/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.9178 - val_loss: 1.5665 - val_accuracy: 0.5500\n",
            "Epoch 29/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.9261 - val_loss: 1.6297 - val_accuracy: 0.5394\n",
            "Epoch 30/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.9294 - val_loss: 1.5961 - val_accuracy: 0.5362\n",
            "Epoch 31/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9384 - val_loss: 1.6735 - val_accuracy: 0.5431\n",
            "Epoch 32/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.2369 - accuracy: 0.9425 - val_loss: 1.6584 - val_accuracy: 0.5356\n",
            "Epoch 33/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9488 - val_loss: 1.7203 - val_accuracy: 0.5275\n",
            "Epoch 34/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9567 - val_loss: 1.8000 - val_accuracy: 0.5312\n",
            "Epoch 35/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9605 - val_loss: 1.7961 - val_accuracy: 0.5350\n",
            "Epoch 36/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.9605 - val_loss: 1.8155 - val_accuracy: 0.5331\n",
            "Epoch 37/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9608 - val_loss: 1.8197 - val_accuracy: 0.5344\n",
            "Epoch 38/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9639 - val_loss: 1.8930 - val_accuracy: 0.5244\n",
            "Epoch 39/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.9681 - val_loss: 1.8671 - val_accuracy: 0.5375\n",
            "Epoch 40/40\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9669 - val_loss: 1.9375 - val_accuracy: 0.5294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "hVc_95bRgKvQ",
        "outputId": "e4d9a28b-6baa-4a1b-f4ea-3fdad947e480"
      },
      "source": [
        "metrics = history.history\n",
        "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "DJ6LBJPdcx_q",
        "outputId": "6a1d873a-5043-41f2-fb84-9c533b58c51a"
      },
      "source": [
        "scores, embeddings, spectrogram = yamnet_model(zero_pad_the_waveforms(get_waveform_and_label_in_integer('/content/data/mini_speech_commands/right/0227998e_nohash_0.wav')[0]))\n",
        "print(embeddings)\n",
        "embeddings = tf.reduce_mean(embeddings, 0)\n",
        "result = my_model(embeddings).numpy()\n",
        "print(result)\n",
        "\n",
        "#infered_class = commands[result.mean(axis=0).argmax()]\n",
        "#print(f'The main sound is: {infered_class}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.05651987 0.07747456 0.         ... 0.         0.03957902 0.        ]\n",
            " [0.10405616 0.13227785 0.3524423  ... 0.22695433 0.         0.        ]], shape=(2, 1024), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-a2526e334f0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         training=training_mode):\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    233\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer my_model is incompatible with the layer: : expected min_ndim=2, found ndim=1. Full shape received: (1024,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmTApLvd2T71"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}